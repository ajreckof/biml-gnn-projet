{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonhoure Timoth√© et Martinez Christophe\n",
    "\n",
    "# GNN : Projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "\n",
    "import torch\n",
    "from torch_geometric.utils import from_networkx, train_test_split_edges\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from GCN import GCN, SimpleGCN\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the network\n",
    "G = nx.read_graphml(\"data/airportsAndCoordAndPop.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_positions = {node: (data['lon'], data['lat']) for node, data in G.nodes(data=True)}\n",
    "labels = {node: (data['city_name']) for node, data in G.nodes(data=True)}\n",
    "nx.draw_networkx_edges\n",
    "nx.draw(G, pos=node_positions, with_labels=True, labels=labels, font_size=1, node_size=10, width = 0.1)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 27094], population=[3363], country=[3363], city_name=[3363], x=[3363, 2])\n",
      "2\n",
      "212\n"
     ]
    }
   ],
   "source": [
    "G.graph = {} \n",
    "data = from_networkx(G, group_node_attrs=[\"lon\",\"lat\"])\n",
    "\n",
    "print(data)\n",
    "print(data.num_features)\n",
    "print(len(set(data.country)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "integer_labels = encoder.fit_transform(data.country)\n",
    "target_tensor = torch.tensor(integer_labels, dtype=torch.long)\n",
    "data.y = target_tensor\n",
    "data.num_classes = len(set(data.country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = data.num_nodes\n",
    "train_ratio = 0.80 # 80% of nodes for training\n",
    "# Randomly creating a mask\n",
    "mask = torch.rand(num_nodes) < train_ratio\n",
    "data.train_mask = mask\n",
    "data.test_mask = data.train_mask\n",
    "# remove the attributes for the nodes that are not in the training set\n",
    "temp = torch.zeros((num_nodes, 2), dtype=torch.float)\n",
    "temp[data.train_mask] = data.x[data.train_mask]\n",
    "data.x = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0.0000,    0.0000],\n",
      "        [   0.0000,    0.0000],\n",
      "        [-149.6000,  -17.5500],\n",
      "        ...,\n",
      "        [-113.2039,   54.7431],\n",
      "        [ 146.6000,   -6.1333],\n",
      "        [ 147.2500,   -6.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(data.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(dim_in=data.num_features, dim_h=100, dim_out=data.num_classes)\n",
    "model.fit(data, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7467\n"
     ]
    }
   ],
   "source": [
    "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f\"Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 27094], population=[3363], country=[3363], city_name=[3363], x=[3363, 3])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "G.graph = {} \n",
    "encoder = LabelEncoder()\n",
    "encoder.fit([G.nodes[node][\"country\"] for node in G.nodes])\n",
    "\n",
    "for node in G.nodes :\n",
    "    G.nodes[node][\"country_code\"] = encoder.transform([G.nodes[node][\"country\"]])[0]\n",
    "\n",
    "\n",
    "data = from_networkx(G, group_node_attrs=[\"lon\",\"lat\",\"country_code\"])\n",
    "\n",
    "print(data)\n",
    "print(data.num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(population=[3363], country=[3363], city_name=[3363], x=[3363, 3], val_pos_edge_index=[2, 677], test_pos_edge_index=[2, 1354], train_pos_edge_index=[2, 23032], train_neg_adj_mask=[3363, 3363], val_neg_edge_index=[2, 677], test_neg_edge_index=[2, 1354])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timothebonhoure/miniconda3/lib/python3.10/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from encoder import Encoder\n",
    "\n",
    "dt = data.__copy__()\n",
    "train_test_split_edges(dt)\n",
    "print(dt)\n",
    "dt.num_classes = len(set(data.country))\n",
    "\n",
    "encoder = Encoder(in_channels=dt.num_features, out_channels=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  :  (0.4881831610044313, 0.4942293862047879)\n",
      "100  :  (0.8305354886991658, 0.7571668982627946)\n",
      "200  :  (0.8743260845375266, 0.8104384973279698)\n",
      "300  :  (0.9203688834876257, 0.8855916985121329)\n",
      "400  :  (0.9318295372974436, 0.9382725169564655)\n",
      "500  :  (0.9440783803774145, 0.949852914119183)\n",
      "600  :  (0.948329147839216, 0.9532897754640356)\n",
      "700  :  (0.9559170377610844, 0.9582607429820684)\n",
      "800  :  (0.9066677539496737, 0.880456889442105)\n",
      "900  :  (0.941737540064015, 0.9399751309269405)\n",
      "1000  :  (0.9506538970913907, 0.9482737577995091)\n",
      "1100  :  (0.9525324603068976, 0.9498349502591947)\n",
      "1200  :  (0.9548664823740152, 0.9519423706036194)\n",
      "1300  :  (0.9543330227849427, 0.9522451860572073)\n",
      "1400  :  (0.9583339697029863, 0.9620097021855012)\n",
      "1500  :  (0.9608812665137926, 0.96411776116499)\n",
      "1600  :  (0.9582164231370914, 0.9623068215861276)\n",
      "1700  :  (0.9609325397258304, 0.9642769280857345)\n",
      "1800  :  (0.959317979006347, 0.963134592986058)\n",
      "1900  :  (0.7345743996125055, 0.6554107812450941)\n",
      "2000  :  (0.9177059492198834, 0.9034276051406854)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.916870850415313, 0.9157826081584531)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import VGAE\n",
    "\n",
    "vgae = VGAE(encoder)\n",
    "\n",
    "def fit(model, data, epochs):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    model.train()\n",
    "    for epoch in range(epochs+1):\n",
    "        if epoch % 100 == 0 :\n",
    "            z = vgae.encode(dt.x, dt.train_pos_edge_index)\n",
    "            print(epoch, \" : \", vgae.test(z, dt.test_pos_edge_index, dt.test_neg_edge_index))\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(dt.x, dt.train_pos_edge_index)\n",
    "        loss = model.recon_loss(z, data.train_pos_edge_index) + (1 / dt.num_nodes) * model.kl_loss()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "fit(vgae, dt, 2000)\n",
    "\n",
    "z = vgae.encode(dt.x, dt.train_pos_edge_index)\n",
    "vgae.test(z, dt.test_pos_edge_index, dt.test_neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 133,   94,  167,  ..., 1094,  133,  249],\n",
      "        [ 350,  142,  680,  ..., 1260, 1245,  448]]) tensor([[ 331,  263,  344,  ...,  299,    2,  424],\n",
      "        [1320, 1015, 1835,  ..., 3106,  526,  965]])\n"
     ]
    }
   ],
   "source": [
    "print(dt.test_pos_edge_index, dt.test_neg_edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1354])\n",
      "torch.Size([2, 1354])\n"
     ]
    }
   ],
   "source": [
    "print(dt.test_pos_edge_index.shape)\n",
    "print(dt.test_neg_edge_index.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- chercher sur differentes couches \n",
    "- tester dropout\n",
    "- tester entrainer decodeur"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "a5a318b75a7586e7126ee807ac3c15c9d32b27634cac574e72ad2f13c9c76b5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
